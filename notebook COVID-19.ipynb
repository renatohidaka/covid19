{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research notebook: \n",
    "## The quest for better machine learning models to forecast COVID-19-related infections: A case study in the state of Pará-Brazil\n",
    "## authors: Renato Hidaka Torres; Wilson Rogério Soares; Orlando Ohashi; Gustavo Pessin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../data/dataset_new.csv\")\n",
    "\n",
    "def create_dataset():    \n",
    "    \n",
    "    new_cases = [0]\n",
    "    new_deaths = [0]\n",
    "\n",
    "    for id in range(1, len(data['confirmados'].values)):\n",
    "\n",
    "        new_cases.append(data['confirmados'].values[id] - data['confirmados'].values[id-1])\n",
    "        new_deaths.append(data['mortes'].values[id] - data['mortes'].values[id - 1])\n",
    "\n",
    "    data['novos casos'] = new_cases\n",
    "    data['novas mortes'] = new_deaths\n",
    "    data.to_csv('../data/dataset_new.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create windonw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_size(N):\n",
    "    return np.array(data[:-N].values),  data['confirmados'][N:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution1D\n",
    "from preprocessing import create_dataset as pre\n",
    "from keras.layers import Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def create_model(L, F):\n",
    "    def cnn():\n",
    "        model = Sequential()\n",
    "        model.add(Convolution1D(F, 2, input_shape=(8,1), activation='relu'))\n",
    "\n",
    "        for i in range(1,L):\n",
    "            model.add(Convolution1D(F, 2, activation='relu'))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "    return cnn\n",
    "\n",
    "for w in range(1, 11):\n",
    "    X, y = pre.create_window_size(w)\n",
    "    \n",
    "    X = np.expand_dims(X, axis=2)\n",
    "    print(X.shape)\n",
    "    \n",
    "    \n",
    "    X_train = X[:len(X)-10]\n",
    "    X_val = X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_val = y[len(y)-10:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33)\n",
    "    \n",
    "    print('window=',w)\n",
    "    for L in range(1,7):\n",
    "        for N in range(10, 70, 10):\n",
    "            model = KerasRegressor(build_fn=create_model(L,N), epochs=100, batch_size=15, verbose=0)\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "    \n",
    "            y_pred = []\n",
    "    \n",
    "            for i in range(100):\n",
    "                aux = model.predict(X_val)\n",
    "                y_pred.append(aux)\n",
    "    \n",
    "            y_pred = np.mean(y_pred, axis=0)\n",
    "            y_std = np.std(y_pred, axis=0)\n",
    "    \n",
    "            y_pred = [int(x) for x in y_pred]\n",
    "    \n",
    "            MAX = max(y_val)\n",
    "            MIN = min(y_val)\n",
    "    \n",
    "            a = []\n",
    "            b = []\n",
    "            for y1, y2 in zip(y_val, y_pred):\n",
    "                a.append((y1-MIN)/(MAX-MIN))\n",
    "                b.append((y2 - MIN) / (MAX - MIN))\n",
    "    \n",
    "    \n",
    "            print('L=', L, 'N=', N)\n",
    "    \n",
    "            print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "            print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "            print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "            print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "            print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def create_model(L, F):\n",
    "    def lstm():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(F))\n",
    "\n",
    "        for i in range(1,L):\n",
    "            model.add(Dense(F))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "    return lstm\n",
    "\n",
    "\n",
    "for w in range(1, 11):\n",
    "    X, y = pre.create_window_size(w)\n",
    "    \n",
    "    X_train = X[:len(X)-10]\n",
    "    X_val =  X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_val =  y[len(y)-10:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33)\n",
    "    \n",
    "    \n",
    "    print('window=',w)\n",
    "    for L in range(1,7):\n",
    "        for N in range(10, 70, 10):\n",
    "            model = KerasRegressor(build_fn=create_model(L,N), epochs=100, batch_size=15, verbose=0)\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "    \n",
    "            y_pred = []\n",
    "    \n",
    "            for i in range(100):\n",
    "                aux = model.predict(X_val)\n",
    "                y_pred.append(aux)\n",
    "    \n",
    "            y_pred = np.mean(y_pred, axis=0)\n",
    "            y_std = np.std(y_pred, axis=0)\n",
    "    \n",
    "            y_pred = [int(x) for x in y_pred]\n",
    "    \n",
    "            maior = max(y_val)\n",
    "            menor = min(y_val)\n",
    "    \n",
    "            a = []\n",
    "            b = []\n",
    "            for y1, y2 in zip(y_val, y_pred):\n",
    "                a.append((y1-menor)/(maior-menor))\n",
    "                b.append((y2 - menor) / (maior - menor))\n",
    "    \n",
    "    \n",
    "            y_test = np.array(a)\n",
    "            y_pred = np.array(b)\n",
    "    \n",
    "            print('L=', L, 'N=', N)\n",
    "    \n",
    "            print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "            print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "            print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "            print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "            print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for w in range(1, 11) :\n",
    "    X, y = pre.create_window_size(w)\n",
    "    \n",
    "    X_train = X[:len(X)-10]\n",
    "    X_test = X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_test = y[len(y)-10:]\n",
    "    \n",
    "    regressor = GradientBoostingRegressor()\n",
    "    \n",
    "    param_grid = {'n_estimators':[75,100,125,150,175,200],\n",
    "                  'min_samples_split':range(5,45,5), 'max_depth':range(2,10,2),  'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "    \n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"window\", w)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for w in range(1, 11):\n",
    "    X, y = pre.create_window_size(w)\n",
    "    \n",
    "    X_train = X[:len(X)-10]\n",
    "    X_test = X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_test = y[len(y)-10:]\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "    \n",
    "    param_grid = {'n_estimators':[75,100,125,150,175,200],\n",
    "                  'min_samples_split':range(5,45,5), 'max_depth':range(2,10,2), 'criterion':['mse', 'mae'], 'max_features':['sqrt', 'log2']}\n",
    "    \n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"window\", w)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "for w in range(1,11):\n",
    "    X, y = pre.create_window_size(w)\n",
    "\n",
    "    X_train = X[:len(X)-10]\n",
    "    X_test = X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_test = y[len(y)-10:]\n",
    "\n",
    "    regressor = LinearSVR()\n",
    "\n",
    "    param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "    param_grid = [{'C': param_range}]\n",
    "\n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"window\", w)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution1D\n",
    "from preprocessing import create_dataset as pre\n",
    "from keras.layers import Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def create_model(L = 1, N=60):\n",
    "\n",
    "    def cnn():\n",
    "        model = Sequential()\n",
    "        model.add(Convolution1D(N, 3, input_shape=(8,1), activation='relu'))#120 ou 60\n",
    "\n",
    "        for i in range(1,L):\n",
    "            model.add(Convolution1D(N,2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def train_test(L, N, window):\n",
    "    X, y = pre.create_window_size(window)\n",
    "    X = np.expand_dims(X, axis=2)\n",
    "    X_train = X[:len(X)-10]\n",
    "    X_val =  X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_val =  y[len(y)-10:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33)\n",
    "\n",
    "    model = KerasRegressor(build_fn=create_model(L, N), epochs=150, batch_size=15, verbose=0)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=15, verbose=0)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_std = np.std([abs(yt-yp) for yt, yp in zip(y_val, y_pred)])\n",
    "\n",
    "    y_pred = [int(x) for x in y_pred]\n",
    "\n",
    "    print(\"CNN\"+str(window),\"=\", y_pred)\n",
    "\n",
    "    maior = max(y_val)\n",
    "    menor = min(y_val)\n",
    "    a = []\n",
    "    b = []\n",
    "    for y1, y2 in zip(y_val, y_pred):\n",
    "        a.append((y1-menor)/(maior-menor))\n",
    "        b.append((y2 - menor) / (maior - menor))\n",
    "\n",
    "\n",
    "    y_val = np.array(a)\n",
    "    y_pred = np.array(b)\n",
    "\n",
    "\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "    print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "    print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "layers = [6, 4, 3, 4, 5, 5, 6, 6, 4, 5]\n",
    "neuron = [40, 50, 60, 60, 60, 20, 60, 60, 10, 60]\n",
    "\n",
    "for L, N, w in zip(layers, neuron, range(1,11)):\n",
    "    train_test(L, N, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def create_model(L=1, N=60):\n",
    "    def mlp():\n",
    "        model = Sequential()\n",
    "        for i in range(L):\n",
    "            model.add(Dense(N))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "        return model\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_test(L, N, window):\n",
    "\n",
    "    X, y = pre.create_window_size(window)\n",
    "\n",
    "    X_train = X[:len(X) - 10]\n",
    "    X_val = X[len(X) - 10:]\n",
    "    y_train = y[:len(y) - 10]\n",
    "    y_val = y[len(y) - 10:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "\n",
    "    model = KerasRegressor(build_fn=create_model(L, N), epochs=500, batch_size=32, verbose=0)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32, verbose=0)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"MLP\", scores)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_std = np.std([abs(yt - yp) for yt, yp in zip(y_val, y_pred)])\n",
    "\n",
    "    y_pred = [int(x) for x in y_pred]\n",
    "\n",
    "    print('Window=', window)\n",
    "    print(\"MLP\"+str(window),\"=\", y_pred)\n",
    "    print(y_std)\n",
    "\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "    print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "    print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "\n",
    "    \n",
    "for L, N, w in zip(layers, neuron, range(1,11)):\n",
    "    train_test(L, N, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from preprocessing import create_dataset as pre\n",
    "\n",
    "\n",
    "def train_test(window = 1):\n",
    "\n",
    "    X, y = pre.create_window_size(window)\n",
    "\n",
    "    X_train = X[:len(X) - 10]\n",
    "    X_val = X[len(X) - 10:]\n",
    "    y_train = y[:len(y) - 10]\n",
    "    y_val = y[len(y) - 10:]\n",
    "\n",
    "    regressor = GradientBoostingRegressor()#Here: insert hyperparameters selected on Grid Search\n",
    "    regressor.fit(X_train, y_train)\n",
    "    scores = cross_val_score(regressor, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"CV\", scores)\n",
    "\n",
    "    y_pred = regressor.predict(X_val)\n",
    "    y_pred = [int(x) for x in y_pred]\n",
    "\n",
    "    print('Window=', window)\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "    print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "    print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "    print()\n",
    "\n",
    "\n",
    "for window in range(1,11):\n",
    "    train_test(window)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from preprocessing import create_dataset as pre\n",
    "\n",
    "\n",
    "def train_test(window = 1):\n",
    "\n",
    "    X, y = pre.create_window_size(window)\n",
    "\n",
    "    X_train = X[:len(X) - 10]\n",
    "    X_val = X[len(X) - 10:]\n",
    "    y_train = y[:len(y) - 10]\n",
    "    y_val = y[len(y) - 10:]\n",
    "\n",
    "    regressor = RandomForestRegressor()#Here: insert hyperparameters selected on Grid Search\n",
    "    regressor.fit(X_train, y_train)\n",
    "    scores = cross_val_score(regressor, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"CV\", scores)\n",
    "\n",
    "    y_pred = regressor.predict(X_val)\n",
    "    y_pred = [int(x) for x in y_pred]\n",
    "\n",
    "    print('Window=', window)\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\n",
    "    print('R2:', metrics.r2_score(y_val, y_pred))\n",
    "    print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_val, y_pred))\n",
    "    print()\n",
    "\n",
    "\n",
    "for window in range(1,11):\n",
    "    train_test(window)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from preprocessing import create_dataset as pre\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def train_test(window=1, c=1):\n",
    "    X, y = pre.create_window_size(window)\n",
    "\n",
    "    X_train = X[:len(X)-10]\n",
    "    X_test = X[len(X)-10:]\n",
    "    y_train = y[:len(y)-10]\n",
    "    y_test = y[len(y)-10:]\n",
    "\n",
    "    regressor = LinearSVR(C=c)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(regressor, X_train, y_train, cv=10)\n",
    "    print(\"MLP\", scores)\n",
    "\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred = [int(x) for x in y_pred]\n",
    "\n",
    "    print(\"SVM\"+str(window),\"=\", y_pred)\n",
    "\n",
    "    maior = max(y_test)\n",
    "    menor = min(y_test)\n",
    "\n",
    "    a = []\n",
    "    b = []\n",
    "\n",
    "    for y1, y2 in zip(y_test, y_pred):\n",
    "        a.append((y1 - menor)/(maior-menor))\n",
    "        b.append((y2 - menor) / (maior - menor))\n",
    "\n",
    "    y_test = np.array(a)\n",
    "    y_pred = np.array(b)\n",
    "    \n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('R2:', metrics.r2_score(y_test, y_pred))\n",
    "    print('Mean Absolute Percentage Error:', metrics.regression.explained_variance_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "C = [0.001, 1, 1, 1, 0.1, 0.1, 0.1, 0.001, 0.1, 0.1]\n",
    "for window, c in zip(range(1,11), C):\n",
    "    train_test(window, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Auto Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "data = pd.read_csv(\"../data/dataset_new.csv\")\n",
    "df = pd.DataFrame()\n",
    "df['y'] = data['confirmados'][:len(data)-10]\n",
    "\n",
    "model = AutoReg(df['y'].values, lags=1)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# make prediction\n",
    "print(len(data))\n",
    "yhat = model_fit.predict(0)\n",
    "print(*yhat, sep=\"\\n\")\n",
    "print(len(yhat))\n",
    "\n",
    "yhat = model_fit.predict(55,64)\n",
    "print(list(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "\n",
    "data = pd.read_csv(\"../data/dataset_new.csv\")\n",
    "df = pd.DataFrame()\n",
    "df['y'] = data['confirmados'][:len(data)-10]\n",
    "\n",
    "model = Prophet(seasonality_mode='multiplicative')\n",
    "model.add_seasonality(name=\"yearly\", period=365.25, fourier_order=10)\n",
    "model.fit(soma);\n",
    "future = model.make_future_dataframe(periods=10, freq = 'd')\n",
    "forecast = model.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "model.plot(forecast,uncertainty=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction window of the observed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test =  [9059.0, 10344.0, 11479.0, 12626.0, 13464.0, 14201.0, 15467.0, 17177.0, 18929.0, 20537.0]\n",
    "\n",
    "LR1 = [8666, 9588, 10913, 12234, 13531, 14579, 15508, 16757, 18499, 20299]\n",
    "LR2 = [8494, 9085, 9936, 11268, 12755, 14189, 15445, 16435, 17638, 19385]\n",
    "LR3 = [8471, 9048, 9522, 10130, 11449, 13000, 14589, 15973, 17039, 18316]\n",
    "LR4 = [9098, 9710, 10298, 11308, 12676, 14308, 15975, 17532, 18864, 19921]\n",
    "LR5 = [8782, 9758, 10663, 11040, 11963, 13484, 15232, 17184, 18897, 20489]\n",
    "LR6 = [8429, 9554, 10516, 10918, 11758, 12686, 13615, 15206, 17001, 18847]\n",
    "LR7 = [9556, 9146, 10559, 11573, 11816, 12876, 13735, 14094, 15541, 17488]\n",
    "LR8 = [9267, 9844, 10116, 11415, 12367, 12696, 13691, 14522, 15459, 17344]\n",
    "LR9 = [8616, 9912, 11103, 10943, 12254, 13142, 13686, 14460, 14886, 15406]\n",
    "LR10 = [8600, 9013, 10735, 11721, 11604, 13212, 13832, 13660, 14955, 15132]\n",
    "\n",
    "\n",
    "SVM1 = [8851, 9914, 11304, 12579, 13848, 14807, 15664, 17009, 18850, 20756]\n",
    "SVM2 = [8776, 9486, 10514, 11948, 13419, 14852, 16043, 16981, 18308, 20200]\n",
    "SVM3 = [8777, 9137, 9725, 10674, 12053, 13723, 15265, 16718, 17774, 18918]\n",
    "SVM4 = [8756, 9353, 9795, 10412, 11494, 13025, 14733, 16355, 17790, 18831]\n",
    "SVM5 = [10037, 10958, 11762, 12250, 13002, 14398, 16309, 18461, 20472, 22270]\n",
    "SVM6 = [8774, 9685, 10617, 11390, 11852, 12551, 13804, 15556, 17613, 19546]\n",
    "SVM7 = [10084, 10325, 11399, 12503, 13424, 13939, 14780, 16141, 18060, 20421]\n",
    "SVM8 = [10155, 9889, 11104, 12405, 13537, 13951, 15147, 16607, 18628, 21196]\n",
    "SVM9 = [9703, 11103, 11915, 12180, 13359, 14683, 15991, 16399, 17254, 18962]\n",
    "SVM10 = [9936, 10873, 12673, 12932, 13649, 15032, 16409, 17455, 18220, 19347]\n",
    "\n",
    "RF1 = [7464.1, 7464.1, 7464.1, 7438.5, 7438.5, 7035.1, 7438.5, 7464.1, 7464.1, 7464.1]\n",
    "RF2 = [6864.6, 6864.6, 6864.6, 6864.6, 6864.6, 6864.6, 6723.3, 6723.3, 6864.6, 6864.6]\n",
    "RF3 = [6755.9, 8069.0, 7996.9, 7996.9, 7996.9, 7924.8, 7924.8, 7536.2, 7536.2, 7996.9]\n",
    "RF4 = [5991.2, 5888.3, 5991.2, 5991.2, 5991.2, 5991.2, 5991.2, 5991.2, 5991.2, 5991.2]\n",
    "RF5 = [7769.8, 7769.8, 7130.5, 7769.8, 7769.8, 7769.8, 7769.8, 7769.8, 7769.8, 7769.8]\n",
    "RF6 = [7348.2, 7329.3, 7329.3, 5930.7, 7329.3, 7329.3, 7329.3, 7329.3, 7329.3, 7329.3]\n",
    "RF7 = [7545.6, 7545.6, 7487.2, 7487.2, 7545.6, 7487.2, 7487.2, 7487.2, 7487.2, 7487.2]\n",
    "RF8 = [6045.1, 5083.9, 5824.3, 5824.3, 5824.3, 5280.2, 5824.3, 5824.3, 5824.3, 5824.3]\n",
    "RF9 = [6686.0, 6628.7, 6615.9, 6615.9, 6821.2, 6821.2, 6686.0, 6821.2, 6821.2, 6821.2]\n",
    "RF10 = [7810.2, 7065.1, 7396.4, 7396.4, 7551.4, 7810.2, 7810.2, 6687.5, 7810.2, 7810.2]\n",
    "\n",
    "GB1 = [7871.3881846296335, 7871.3881846296335, 7871.3881846296335, 7710.409492846894, 7710.409492846894, 7707.083925167276, 7710.409492846894, 7871.3881846296335, 7871.3881846296335, 7871.3881846296335]\n",
    "GB2 = [7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312, 7837.998960945312]\n",
    "GB3 = [6680.092299232183, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603, 6626.087673621603]\n",
    "GB4 = [8064.369990171665, 7327.439788652379, 8064.369990171665, 8011.8279573819245, 8011.8279573819245, 8011.8279573819245, 8011.8279573819245, 8011.8279573819245, 7907.179868792137, 8011.8279573819245]\n",
    "GB5 = [7498.880402259262, 7498.880402259262, 7451.377593613323, 7498.880402259262, 7498.880402259262, 7498.880402259262, 7498.880402259262, 7498.880402259262, 7498.880402259262, 7498.880402259262]\n",
    "GB6 = [7442.358979848454, 7737.7596058309555, 7737.7596058309555, 7787.695732973893, 7737.7596058309555, 7737.7596058309555, 7737.7596058309555, 7737.7596058309555, 7737.7596058309555, 7737.7596058309555]\n",
    "GB7 = [7355.683403081797, 8023.93002916676, 7726.296442082717, 7726.296442082717, 7036.19592708027, 7726.296442082717, 7726.296442082717, 7726.296442082717, 7726.296442082717, 7726.296442082717]\n",
    "GB8 = [7701.865588902501, 7585.568905332606, 7592.50608774121, 7626.499871798507, 7626.499871798507, 7349.139470345359, 7626.499871798507, 7626.499871798507, 7626.499871798507, 7626.499871798507]\n",
    "GB9 = [7412.081136901952, 7237.123392831925, 7728.376972157348, 7902.562347150866, 8068.733425200793, 8068.733425200793, 7158.961894077294, 8068.733425200793, 8068.733425200793, 8068.733425200793]\n",
    "GB10 = [7330.046472502023, 7238.018765427782, 7330.046472502023, 7320.199684299847, 7330.046472502023, 7347.804086449134, 7347.804086449134, 7183.218527487421, 7347.804086449134, 7347.804086449134]\n",
    "\n",
    "CNN1 = [8902, 9987, 11446, 12736, 13993, 14885, 16284, 17685, 19529, 21010]\n",
    "CNN2 = [8207, 8971, 9932, 11216, 12439, 13595, 14427, 16236, 17474, 19108]\n",
    "CNN3 = [8612, 9127, 9985, 11047, 12487, 13953, 15306, 16369, 18300, 19616]\n",
    "CNN4 = [8897, 9251, 9906, 10853, 12051, 13620, 15023, 16384, 17295, 19395]\n",
    "CNN5 = [8783, 9391, 9774, 10391, 11316, 12500, 14015, 15424, 16799, 17773]\n",
    "CNN6 = [9344, 10301, 11002, 11386, 12376, 13636, 15312, 17576, 19460, 21326]\n",
    "CNN7 = [8538, 9612, 10524, 11215, 11615, 12457, 13615, 15139, 17120, 18862]\n",
    "CNN8 = [9172, 9024, 10409, 11492, 12296, 12606, 13756, 15181, 17039, 19475]\n",
    "CNN9 = [9206, 10197, 11151, 12511, 13740, 14752, 15626, 16764, 18457, 20609]\n",
    "CNN10 = [8613, 9236, 10487, 10778, 12001, 13170, 14118, 14767, 15773, 17218]\n",
    "\n",
    "MLP1 = [9014, 10081, 11514, 12833, 14136, 15118, 16158, 17536, 19411, 21241]\n",
    "MLP2 = [8534, 9340, 10441, 11857, 13254, 14586, 15662, 16740, 18039, 19877]\n",
    "MLP3 = [8701, 9210, 10026, 11161, 12656, 14223, 15688, 16932, 18150, 19475]\n",
    "MLP4 = [9158, 9476, 10323, 11395, 12778, 14620, 16191, 17774, 18847, 20392]\n",
    "MLP5 = [9089, 9937, 10314, 11243, 12466, 13927, 15875, 17595, 19316, 20543]\n",
    "MLP6 = [9086, 10155, 10995, 11313, 12423, 13768, 15418, 17691, 19584, 21522]\n",
    "MLP7 = [8531, 10046, 11263, 12187, 12299, 13646, 15130, 17111, 19650, 21477]\n",
    "MLP8 = [10042, 9419, 10709, 11994, 13052, 13267, 14512, 15899, 17845, 20287]\n",
    "MLP9 = [9152, 10426, 10889, 11701, 13005, 14279, 15069, 16057, 17554, 19499]\n",
    "MLP10 = [9806, 10709, 12343, 12640, 13540, 15019, 16563, 17572, 18580, 20188]\n",
    "\n",
    "AR = [8005.5756863892475, 8788.678820126106, 9570.346974529433, 10419.343897213972, 11341.468932841171, 12343.020951006043, 13430.841372677867, 14612.36090271137, 15895.650287649703, 17289.475445536602]\n",
    "\n",
    "PROPHET = [8271.167728112437, 8644.964341092684, 8920.769274456597, 9514.963157993063, 9711.110557018099, 10259.978544495567, 11114.728071108544, 10475.055172062208, 11181.421580707369, 11908.313992589217]\n",
    "\n",
    "X = ['12/05/2020','13/05/2020','14/05/2020','15/05/2020','16/05/2020','17/05/2020','18/05/2020','19/05/2020','20/05/2020','21/05/2020']\n",
    "plt.plot(X,y_test, linewidth=4, linestyle='solid', color=\"black\", label='True')\n",
    "\n",
    "plt.plot(X,LR10, linewidth=4, linestyle='dashed', color=\"blue\", label='Linear Regression')\n",
    "plt.plot(X,SVM10, linewidth=4, linestyle='dashed', color=\"red\", label='Linear SVM')\n",
    "plt.plot(X,CNN10, linewidth=4, linestyle='dashed', color=\"purple\", label='Convolutional Neural Network')\n",
    "plt.plot(X,MLP10, linewidth=4, linestyle='dashed', color=\"green\", label='Multilayer Perceptron')\n",
    "\n",
    "plt.plot(X,AR, linewidth=4, linestyle='dashed', color=\"cyan\", label='AutoRegression')\n",
    "plt.plot(X,PROPHET, linewidth=4, linestyle='dashed', color=\"orange\", label='Prophet')\n",
    "\n",
    "plt.title('Window 10', fontsize=18)\n",
    "plt.ylabel(\"Confirmed cases\", fontsize=18)\n",
    "plt.xlabel(\"Days\", fontsize=18)\n",
    "\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radar chart by windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "categories = ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2']\n",
    "\n",
    "N = len(categories)\n",
    "\n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "\n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# If you want the first axis to be on top:\n",
    "ax.set_theta_offset(pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "\n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(angles[:-1], categories, color='grey', size=16)\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1], [\"0.4\", \"0.5\", \"0.6\", \"0.7\", \"0.8\", \"0.9\", \"0.95\", \"1\"], color=\"grey\", size=10)\n",
    "plt.ylim(0.4, 1)\n",
    "\n",
    "# Plot data\n",
    "#ax.plot(angles, values, linewidth=2, linestyle='solid', color=\"blue\")\n",
    "\n",
    "# Fill area\n",
    "#ax.fill(angles, values, color='blue', alpha=0.1)\n",
    "\n",
    "#Replace theses data for each window\n",
    "LR =  [0.9679299529534762, 0.8856733526515179, 0.9986587650986587, 0.9633771259819591, 0.9858124297310489, 0.9679299529534762]\n",
    "SVM =  [0.9781059418017076, 0.9296331014123942, 0.9993191935079422, 0.9739077311822494, 0.9927984352808236, 0.9781059418017076]\n",
    "CNN =  [0.9528158215717024, 0.9132517997237986, 0.9981613909543264, 0.957120995281215, 0.9805512106741805, 0.9528158215717024]\n",
    "MLP =  [0.9618836034152292, 0.9129720522743806, 0.9979186658015982, 0.954378358223297, 0.9779836662739194, 0.9618836034152292]\n",
    "\n",
    "\n",
    "\n",
    "# Plot data\n",
    "plt.title('Window 1', fontsize=20)\n",
    "ax.plot(angles, LR, linewidth=4, linestyle='solid', color=\"blue\", label=\"Linear Regression\")\n",
    "ax.plot(angles, SVM, linewidth=4, linestyle='solid', color=\"red\", label=\"Linear SVM\")\n",
    "ax.plot(angles, CNN, linewidth=4, linestyle='solid', color=\"purple\", label=\"CNN\")\n",
    "ax.plot(angles, MLP, linewidth=4, linestyle='solid', color=\"green\", label=\"MLP\")\n",
    "\n",
    "\n",
    "#ax.legend(loc=1, bbox_to_anchor=(1.2, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "\n",
    "data = pd.read_csv(\"../data/dataset_new.csv\")\n",
    "\n",
    "data = data.rename(columns={'confirmados':'A', 'descartados':'B', 'mortes':'C', 'recuperados':'D', 'Confirmados/100k hab':'E',\n",
    "                     'mortes/confirmados':'F', 'novos casos':'G', 'novas mortes':'H'})\n",
    "\n",
    "corr = data.corr()\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(corr)\n",
    "plt.title(\"Correlation heatmap for the dataset\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
